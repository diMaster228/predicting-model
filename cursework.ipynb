{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN37/+39/66PKO9TcKvxZi0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diMaster228/predicting-model/blob/main/cursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3COdGeRLmrmP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сбор данных, парсинг"
      ],
      "metadata": {
        "id": "Eigqu_yQnn2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "years = list(range(2024, 2018, -1))\n",
        "years\n",
        "standings_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\"\n",
        "all_matches = []\n",
        "import time\n",
        "start_time = time.time()\n",
        "for year in years:\n",
        "    data = requests.get(standings_url)\n",
        "    soup = BeautifulSoup(data.text)\n",
        "    standings_table = soup.select('table.stats_table')[0]\n",
        "\n",
        "    links = [l.get(\"href\") for l in standings_table.find_all('a')]\n",
        "    links = [l for l in links if '/squads/' in l]\n",
        "    team_urls = [f\"https://fbref.com{l}\" for l in links]\n",
        "\n",
        "    previous_season = soup.select(\"a.prev\")[0].get(\"href\")\n",
        "    standings_url = f\"https://fbref.com{previous_season}\"\n",
        "\n",
        "    for team_url in team_urls:\n",
        "        team_name = team_url.split(\"/\")[-1].replace(\"-Stats\", \"\").replace(\"-\", \" \")\n",
        "        data = requests.get(team_url)\n",
        "        matches = pd.read_html(data.text, match=\"Scores & Fixtures\")[0]\n",
        "        soup = BeautifulSoup(data.text)\n",
        "        links = [l.get(\"href\") for l in soup.find_all('a')]\n",
        "        links = [l for l in links if l and 'all_comps/shooting/' in l]\n",
        "        data = requests.get(f\"https://fbref.com{links[0]}\")\n",
        "        shooting = pd.read_html(data.text, match=\"Shooting\")[0]\n",
        "        shooting.columns = shooting.columns.droplevel()\n",
        "        try:\n",
        "            team_data = matches.merge(shooting[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on=\"Date\")\n",
        "        except ValueError:\n",
        "            continue\n",
        "        team_data = team_data[team_data[\"Comp\"] == \"Premier League\"]\n",
        "\n",
        "        team_data[\"Season\"] = year\n",
        "        team_data[\"Team\"] = team_name\n",
        "        all_matches.append(team_data)\n",
        "        time.sleep(1)\n",
        "\n",
        "end_time = time.time()\n",
        "result = end_time - start_time\n",
        "\n"
      ],
      "metadata": {
        "id": "FDuTEwQ0nHkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match_df = pd.concat(all_matches)\n",
        "match_df.columns = [c.lower() for c in match_df.columns]"
      ],
      "metadata": {
        "id": "9zFUyghQnXX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match_df.to_csv(\"matches.csv\")\n",
        "match_df"
      ],
      "metadata": {
        "id": "QIaaiyNQnZ4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение и оценка моделей"
      ],
      "metadata": {
        "id": "b7vQl05mnl_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matches = pd.read_csv(\"matches.csv\", index_col=0)"
      ],
      "metadata": {
        "id": "J20eLpEvozW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del matches[\"comp\"]\n",
        "del matches[\"notes\"]\n",
        "\n",
        "matches[\"date\"] = pd.to_datetime(matches[\"date\"])\n",
        "\n",
        "# Создаем словарь, в котором каждому типу результата (W, D, L) соответствует его значение (2, 1, 0)\n",
        "result_mapping = {'W': 2, 'D': 1, 'L': 0}\n",
        "\n",
        "# Заменяем значения в столбце 'result' на соответствующие значения из словаря result_mapping\n",
        "matches[\"target\"] = matches[\"result\"].replace(result_mapping)\n",
        "\n",
        "matches[\"venue_code\"] = matches[\"venue\"].astype(\"category\").cat.codes\n",
        "matches[\"opp_code\"] = matches[\"opponent\"].astype(\"category\").cat.codes\n",
        "matches[\"hour\"] = matches[\"time\"].str.replace(\":.+\", \"\", regex=True).astype(\"int\")\n",
        "matches[\"day_code\"] = matches[\"date\"].dt.dayofweek\n",
        "matches[\"xg_code\"] = matches[\"xg\"].astype(\"int\")\n",
        "matches[\"xga_code\"] = matches[\"xga\"].astype(\"int\")\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "matches[\"referee_code\"] = label_encoder.fit_transform(matches[\"referee\"])\n"
      ],
      "metadata": {
        "id": "2J_M7Nh-oOLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_predict(model, X_train, y_train, X_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    return model.predict(X_test)\n",
        "\n",
        "def evaluate(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average=None,labels=[0, 1, 2])\n",
        "    return accuracy, precision"
      ],
      "metadata": {
        "id": "vcI4YgaZoR8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = matches[matches[\"date\"] < '2023-08-11']\n",
        "test = matches[matches[\"date\"] > '2023-08-11']\n",
        "\n",
        "predictors = [\"venue_code\", \"opp_code\", \"hour\", \"day_code\", \"xg_code\", \"xga_code\", \"referee_code\"]\n",
        "X_train = train[predictors]\n",
        "y_train = train[\"target\"]\n",
        "X_test = test[predictors]\n",
        "y_test = test[\"target\"]\n",
        "\n",
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=50, min_samples_split=10, random_state=1),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=10000),\n",
        "    'XGBoost': xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(y_train)), eval_metric='merror')\n",
        "}\n"
      ],
      "metadata": {
        "id": "ieBByWKWoU7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precisions = []\n",
        "accuracies = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    y_pred = train_and_predict(model, X_train, y_train, X_test)\n",
        "    combined = pd.DataFrame(dict(actual=y_test, predicted=y_pred))\n",
        "    crosstab = pd.crosstab(index=combined[\"actual\"], columns=combined[\"predicted\"])\n",
        "    accuracy, precision = evaluate(y_test, y_pred)\n",
        "    precisions.append(precision)\n",
        "    accuracies.append(accuracy)\n",
        "    print(crosstab)\n",
        "    print()\n",
        "    print(f\"Accuracy of {model_name} method:\", accuracy)\n",
        "    print(f\"Precision of {model_name} method:\", precision)\n",
        "    print()"
      ],
      "metadata": {
        "id": "xhPSihkOoYE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_matches = matches.groupby(\"team\")\n",
        "group = grouped_matches.get_group(\"Arsenal\")"
      ],
      "metadata": {
        "id": "15AmGeelobZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rolling_averages(group, cols, new_cols):\n",
        "    group = group.sort_values(\"date\")\n",
        "    rolling_stats = group[cols].rolling(3, closed='left').mean()\n",
        "    group[new_cols] = rolling_stats\n",
        "    group = group.dropna(subset=new_cols)\n",
        "    return group\n"
      ],
      "metadata": {
        "id": "eNUxeOpDod_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"gf\", \"ga\", \"sh\", \"sot\", \"dist\", \"fk\", \"pk\", \"pkatt\"]\n",
        "new_cols = [f\"{c}_rolling\" for c in cols]\n",
        "\n",
        "rolling_averages(group, cols, new_cols)\n",
        "\n",
        "matches_rolling = matches.groupby(\"team\").apply(lambda x: rolling_averages(x, cols, new_cols))\n",
        "matches_rolling = matches_rolling.droplevel('team')\n",
        "matches_rolling.index = range(matches_rolling.shape[0])\n",
        "matches_rolling"
      ],
      "metadata": {
        "id": "_D-s8rY7oirt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = matches_rolling[matches_rolling[\"date\"] < '2023-08-11']\n",
        "test = matches_rolling[matches_rolling[\"date\"] > '2023-08-11']\n",
        "\n",
        "X_train = train[predictors]\n",
        "y_train = train[\"target\"]\n",
        "X_test = test[predictors]\n",
        "y_test = test[\"target\"]"
      ],
      "metadata": {
        "id": "5JlvJ6E7o59a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precisions = []\n",
        "accuracies = []\n",
        "\n",
        "  for model_name, model in models.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    y_pred = train_and_predict(model, X_train, y_train, X_test)\n",
        "    combined = pd.DataFrame(dict(actual=y_test, predicted=y_pred))\n",
        "    crosstab = pd.crosstab(index=combined[\"actual\"], columns=combined[\"predicted\"])\n",
        "    accuracy, precision = evaluate(y_test, y_pred)\n",
        "    print(crosstab)\n",
        "    print()\n",
        "    print(f\"Accuracy of {model_name} method:\", accuracy)\n",
        "    print(f\"Precision of {model_name} method:\", precision)\n",
        "    print()"
      ],
      "metadata": {
        "id": "W4QmzkblpkQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined = combined.merge(matches_rolling[[\"date\",\"team\",\"opponent\",\"result\"]],left_index=True, right_index=True)\n",
        "combined"
      ],
      "metadata": {
        "id": "odFUM7u2pqdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MissingDict(dict):\n",
        "    __missing__ = lambda self, key: key\n",
        "\n",
        "map_values = {\"Brighton and Hove Albion\": \"Brighton\", \"Manchester United\": \"Manchester Utd\", \"Newcastle United\": \"Newcastle Utd\", \"Tottenham Hotspur\": \"Tottenham\", \"West Ham United\": \"West Ham\", \"Wolverhampton Wanderers\": \"Wolves\", \"Nottingham Forest\": \"Nott'ham Forest\", \"Sheffield United\": \"Sheffield Utd\"}\n",
        "mapping = MissingDict(**map_values)\n",
        "\n",
        "combined[\"new_team\"] = combined[\"team\"].map(mapping)\n",
        "\n",
        "merged = combined.merge(combined, left_on=[\"date\", \"new_team\"], right_on=[\"date\", \"opponent\"])\n",
        "merged"
      ],
      "metadata": {
        "id": "paZ2vWt-pvXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выберем только нужные столбцы\n",
        "subset = merged[['new_team_x', 'predicted_x', 'new_team_y', 'predicted_y']]\n",
        "\n",
        "# Переименуем столбцы, чтобы они не конфликтовали друг с другом\n",
        "subset.columns = ['team', 'predicted_x', 'opponent', 'predicted_y']\n",
        "\n",
        "# Объединим данные в один датафрейм\n",
        "all_teams = pd.concat([subset[['team', 'predicted_x']], subset[['opponent', 'predicted_y']].rename(columns={'opponent': 'team', 'predicted_y': 'predicted_x'})])\n",
        "\n",
        "# Посчитаем суммарное количество предсказанных очков для каждой команды\n",
        "predicted_points = all_teams.groupby('team')['predicted_x'].sum().reset_index()\n",
        "\n",
        "# Переименуем столбцы для ясности\n",
        "predicted_points.columns = ['Team', 'Predicted Points']\n",
        "\n",
        "predicted_points = predicted_points.sort_values(by='Predicted Points', ascending=False)\n",
        "predicted_points.index = range(predicted_points.shape[0])\n",
        "\n",
        "winner_index = predicted_points['Predicted Points'].idxmax()\n",
        "winner = predicted_points.loc[winner_index, 'Team']\n",
        "\n",
        "print(\"Победитель лиги:\", winner)\n",
        "predicted_points"
      ],
      "metadata": {
        "id": "om8DVhgipwSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://fbref.com/en/comps/9/Premier-League-Stats\""
      ],
      "metadata": {
        "id": "ISNoCk1wp91j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Отправляем GET-запрос на страницу и получаем HTML-код\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "# Используем BeautifulSoup для парсинга HTML-кода\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "# Находим таблицу с данными\n",
        "table = soup.find(\"table\", class_=\"stats_table\")\n",
        "\n",
        "# Преобразуем таблицу в DataFrame с помощью pandas\n",
        "df = pd.read_html(str(table))[0]\n",
        "\n",
        "df;\n",
        "\n",
        "points_df = df[[\"Squad\", \"Pts\"]]\n",
        "points_df = points_df.rename(columns={'Pts': 'Actual_Pts'})\n",
        "points_df"
      ],
      "metadata": {
        "id": "BdYSmKGhqBPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Преобразование датафреймов в строковое представление\n",
        "table1 = points_df.to_string(index=False)\n",
        "table2 = predicted_points.to_string(index=False)\n",
        "\n",
        "# Вывод двух датафреймов в одной области\n",
        "print(tabulate([['Actual Points', 'Predicted Points'], [table1, table2]], headers='firstrow'))"
      ],
      "metadata": {
        "id": "R6K7kDc1qETQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}